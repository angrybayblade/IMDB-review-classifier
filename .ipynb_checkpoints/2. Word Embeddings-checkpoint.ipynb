{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm.cli import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].apply(lambda x:int(x == 'positive')).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOL_FILTER = re.compile(\"[!,.\\\"\\':?()]\")\n",
    "SPECIAL_CHAR_FILTER = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "df['review'] = df.review.apply(lambda x:SPECIAL_CHAR_FILTER.sub(\"\",SYMBOL_FILTER.sub(\"\",x)).lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i.split(\" \") for i in df.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for sent in sentences:\n",
    "    vocab += sent\n",
    "    \n",
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentences,size=48).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(\"hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.zeros((48,))\n",
    "max_len = max([len(s) for s in sentences])\n",
    "\n",
    "def get_vector(w):\n",
    "    if w:\n",
    "        try:\n",
    "            return w2v[w[0]]\n",
    "        except:\n",
    "            return dummy\n",
    "    else:\n",
    "        return dummy\n",
    "    \n",
    "def embed_sent(sent):\n",
    "    sent, = sent\n",
    "    return np.concatenate((np.apply_along_axis(get_vector,1,sent),np.zeros((max_len-len(sent),48))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,x,y,max_len=max_len,vector_size=48,shuffle=True):\n",
    "        self.x = np.array([np.array(i).reshape(-1,1) for i in x]).reshape(-1,1)\n",
    "        self.y = y\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.max_len = max_len\n",
    "        self.vector_size = vector_size\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.x)\n",
    "            \n",
    "    def _flow(self,):\n",
    "        br = len(self,) % self.batch_size\n",
    "        while True:\n",
    "            idx = np.random.permutation(len(self)) if self.shuffle else np.arange(0,len(self))\n",
    "            for batch in idx[:-br].reshape(-1,self.batch_size):\n",
    "                yield np.apply_along_axis(embed_sent,1,self.x[batch]),self.y[batch]                    \n",
    "            yield np.apply_along_axis(embed_sent,1,self.x[idx[-br:]]),self.y[idx[-br:]]\n",
    "                    \n",
    "    \n",
    "    def get_flow(self,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        return self._flow(),np.round(len(self)/batch_size).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,x,Y,y = train_test_split(np.array(sentences),df.sentiment.values)\n",
    "\n",
    "train_ds = Dataset(X,Y)\n",
    "test_ds = Dataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tensor = Input(shape=(2450,48))\n",
    "\n",
    "d1 = MaxPool1D()(in_tensor)\n",
    "d1 = TimeDistributed(Dense(48,))(d1)\n",
    "d1 = BatchNormalization()(d1)\n",
    "d1 = LeakyReLU(0.3)(d1)\n",
    "d1 = Dropout(0.3)(d1)\n",
    "\n",
    "d1 = MaxPool1D()(d1)\n",
    "d1 = TimeDistributed(Dense(96,))(d1)\n",
    "d1 = BatchNormalization()(d1)\n",
    "d1 = LeakyReLU(0.3)(d1)\n",
    "d1 = Dropout(0.3)(d1)\n",
    "\n",
    "d1 = MaxPool1D()(d1)\n",
    "d1 = TimeDistributed(Dense(192,))(d1)\n",
    "d1 = BatchNormalization()(d1)\n",
    "d1 = LeakyReLU(0.3)(d1)\n",
    "d1 = Dropout(0.3)(d1)\n",
    "\n",
    "d1 = GlobalAveragePooling1D()(d1)\n",
    "\n",
    "out = Dense(1,)(d1)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('sigmoid')(out)\n",
    "\n",
    "model = Model(in_tensor,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=loss,optmizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow,train_spe = train_ds.get_flow(8)\n",
    "test_flow,test_spe = test_ds.get_flow(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    generator=train_flow,\n",
    "    steps_per_epoch=train_spe,\n",
    "    validation_data=test_flow,\n",
    "    validation_steps=test_spe,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
